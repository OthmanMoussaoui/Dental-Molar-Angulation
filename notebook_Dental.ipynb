{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:08:50.058283Z",
     "iopub.status.busy": "2023-12-24T15:08:50.057712Z",
     "iopub.status.idle": "2023-12-24T15:09:07.141472Z",
     "shell.execute_reply": "2023-12-24T15:09:07.139321Z",
     "shell.execute_reply.started": "2023-12-24T15:08:50.058248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\otman\\anaconda3\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\otman\\anaconda3\\lib\\site-packages (4.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\otman\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\otman\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:35:16.846738Z",
     "iopub.status.busy": "2023-12-24T15:35:16.846077Z",
     "iopub.status.idle": "2023-12-24T15:35:29.663899Z",
     "shell.execute_reply": "2023-12-24T15:35:29.662938Z",
     "shell.execute_reply.started": "2023-12-24T15:35:16.846694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\otman\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:48:14.616293Z",
     "iopub.status.busy": "2023-12-24T15:48:14.615904Z",
     "iopub.status.idle": "2023-12-24T15:48:14.623528Z",
     "shell.execute_reply": "2023-12-24T15:48:14.622518Z",
     "shell.execute_reply.started": "2023-12-24T15:48:14.616264Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    image_info = {\n",
    "        'filename': filename,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'objects': []\n",
    "    }\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        obj_dict = {\n",
    "            'name': obj.find('name').text,\n",
    "            'coordinates': [int(obj.find('bndbox').find('xmin').text), \n",
    "                            int(obj.find('bndbox').find('ymin').text)]\n",
    "        }\n",
    "        image_info['objects'].append(obj_dict)\n",
    "\n",
    "    return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:52:47.779145Z",
     "iopub.status.busy": "2023-12-24T15:52:47.778229Z",
     "iopub.status.idle": "2023-12-24T15:52:47.788022Z",
     "shell.execute_reply": "2023-12-24T15:52:47.786786Z",
     "shell.execute_reply.started": "2023-12-24T15:52:47.779106Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_image(image, rotation_datagen, scale_factor, num_to_generate, image_info, output_dir):\n",
    "    i = 0\n",
    "    original_size = image.size\n",
    "    scaled_size = (int(original_size[0] * scale_factor), int(original_size[1] * scale_factor))\n",
    "    scaled_image = image.resize(scaled_size, Image.ANTIALIAS)\n",
    "\n",
    "    for batch in rotation_datagen.flow(np.expand_dims(np.array(scaled_image), 0), batch_size=1):\n",
    "        batch_image = Image.fromarray(batch[0].astype('uint8'), 'RGB')\n",
    "        new_filename = f\"aug_{i}_{image_info['filename']}\"\n",
    "        batch_image.save(os.path.join(output_dir, new_filename))\n",
    "        \n",
    "        # Update the dictionary with new filename and (for simplicity) same coordinates\n",
    "        new_image_info = image_info.copy()\n",
    "        new_image_info['filename'] = new_filename\n",
    "        all_data.append(new_image_info)\n",
    "        \n",
    "        i += 1\n",
    "        if i >= num_to_generate:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:56:14.536035Z",
     "iopub.status.busy": "2023-12-24T15:56:14.535275Z",
     "iopub.status.idle": "2023-12-24T15:56:14.540416Z",
     "shell.execute_reply": "2023-12-24T15:56:14.539328Z",
     "shell.execute_reply.started": "2023-12-24T15:56:14.535988Z"
    }
   },
   "outputs": [],
   "source": [
    "rotation_datagen = ImageDataGenerator(rotation_range=20)  # Adjust as needed for rotation\n",
    "\n",
    "# Scale factor for zooming out\n",
    "scale_factor = 0.8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:56:16.517841Z",
     "iopub.status.busy": "2023-12-24T15:56:16.516959Z",
     "iopub.status.idle": "2023-12-24T15:56:16.522339Z",
     "shell.execute_reply": "2023-12-24T15:56:16.521320Z",
     "shell.execute_reply.started": "2023-12-24T15:56:16.517802Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir = r'C:\\Users\\otman\\Downloads\\est\\image'\n",
    "annotation_dir = r'C:\\Users\\otman\\Downloads\\est\\annotation'\n",
    "output_dir = r'C:\\Users\\otman\\Downloads\\est\\augmented_images'\n",
    "output_dir_csv = r'C:\\Users\\otman\\Downloads\\est\\augmented_csv'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir_csv, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:00:01.903398Z",
     "iopub.status.busy": "2023-12-24T16:00:01.903120Z",
     "iopub.status.idle": "2023-12-24T16:00:07.215989Z",
     "shell.execute_reply": "2023-12-24T16:00:07.215156Z",
     "shell.execute_reply.started": "2023-12-24T16:00:01.903373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otman\\AppData\\Local\\Temp\\ipykernel_35656\\4110955332.py:5: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  scaled_image = image.resize(scaled_size, Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "num_augmentations_per_image = 4  # Set so that total is around 200\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        xml_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Load and process the image and XML\n",
    "        image = Image.open(image_path)\n",
    "        image_info = process_xml(xml_path)\n",
    "\n",
    "        # Augment image and update dictionary\n",
    "        augment_image(image, rotation_datagen, scale_factor, num_augmentations_per_image, image_info, output_dir)\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(r'C:\\Users\\otman\\Downloads\\est\\augmented_csv\\dict1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T15:35:37.427791Z",
     "iopub.status.busy": "2023-12-24T15:35:37.427158Z",
     "iopub.status.idle": "2023-12-24T15:35:45.502257Z",
     "shell.execute_reply": "2023-12-24T15:35:45.501454Z",
     "shell.execute_reply.started": "2023-12-24T15:35:37.427757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def augment_image(image, datagen, num_to_generate, image_info, output_dir):\n",
    "    i = 0\n",
    "    for batch in datagen.flow(np.expand_dims(np.array(image), 0), batch_size=1):\n",
    "        batch_image = Image.fromarray(batch[0].astype('uint8'), 'RGB')\n",
    "        new_filename = f\"aug_{i}_{image_info['filename']}\"\n",
    "        batch_image.save(os.path.join(output_dir, new_filename))\n",
    "        \n",
    "        # Update the dictionary with new filename and (for simplicity) same coordinates\n",
    "        new_image_info = image_info.copy()\n",
    "        new_image_info['filename'] = new_filename\n",
    "        all_data.append(new_image_info)\n",
    "        \n",
    "        i += 1\n",
    "        if i >= num_to_generate:\n",
    "            break\n",
    "\n",
    "# Create an ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Adjust as needed for rotation\n",
    "    zoom_range=[0.5, 1.0]  # Adjust as needed for zooming out\n",
    ")\n",
    "\n",
    "# Paths\n",
    "\n",
    "\n",
    "# Process and augment images\n",
    "all_data = []\n",
    "num_augmentations_per_image = 4  # Set so that total is around 200\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        xml_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Load and process the image and XML\n",
    "        image = Image.open(image_path)\n",
    "        image_info = process_xml(xml_path)\n",
    "\n",
    "        # Augment image and update dictionary\n",
    "        augment_image(image, datagen, num_augmentations_per_image, image_info, output_dir)\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv('/kaggle/working/dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:06:55.745040Z",
     "iopub.status.busy": "2023-12-24T16:06:55.744646Z",
     "iopub.status.idle": "2023-12-24T16:06:55.753907Z",
     "shell.execute_reply": "2023-12-24T16:06:55.752785Z",
     "shell.execute_reply.started": "2023-12-24T16:06:55.745009Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xmin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\1262979536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxmin_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxmin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mymin_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mymin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxmax_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxmax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xmin' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def rotate_point(x, y, angle, cx, cy):\n",
    "        angle_rad = np.radians(angle)\n",
    "        x_new = np.cos(angle_rad) * (x - cx) - np.sin(angle_rad) * (y - cy) + cx\n",
    "        y_new = np.sin(angle_rad) * (x - cx) + np.cos(angle_rad) * (y - cy) + cy\n",
    "        return x_new, y_new\n",
    "\n",
    "def update_coordinates(obj_dict, angle, scale_factor, image_size):\n",
    "    # Unpack original image dimensions and bounding box coordinates\n",
    "    original_width, original_height = image_size\n",
    "    xmin, ymin = obj_dict['coordinates']\n",
    "\n",
    "    # Calculate the center of the image\n",
    "    center_x, center_y = original_width / 2, original_height / 2\n",
    "\n",
    "    # Scale the coordinates\n",
    "    xmin_scaled, ymin_scaled = xmin * scale_factor, ymin * scale_factor\n",
    "\n",
    "    # Rotate the scaled coordinates\n",
    "    xmin_rotated, ymin_rotated = rotate_point(xmin_scaled, ymin_scaled, angle, center_x * scale_factor, center_y * scale_factor)\n",
    "\n",
    "    # Update object dictionary with new coordinates\n",
    "    obj_dict['coordinates'] = [int(xmin_rotated), int(ymin_rotated)]\n",
    "\n",
    "    return obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:13:30.129778Z",
     "iopub.status.busy": "2023-12-24T16:13:30.129041Z",
     "iopub.status.idle": "2023-12-24T16:13:30.137451Z",
     "shell.execute_reply": "2023-12-24T16:13:30.136516Z",
     "shell.execute_reply.started": "2023-12-24T16:13:30.129742Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter):\n",
    "    # Load image and parse XML\n",
    "    image = Image.open(image_path)\n",
    "    image_info = process_xml(xml_path)\n",
    "\n",
    "    # Perform scaling and rotation\n",
    "    scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n",
    "    rotated_image = scaled_image.rotate(angle, expand=True)\n",
    "\n",
    "    # Update XML data with transformed coordinates\n",
    "    for obj in image_info['objects']:\n",
    "        update_coordinates(obj, angle, scale_factor, (image.width, image.height))\n",
    "\n",
    "    # Save the transformed image\n",
    "    new_filename = f\"aug_{counter}_{image_info['filename']}\"\n",
    "    rotated_image.save(os.path.join(output_dir, new_filename))\n",
    "\n",
    "    # Update image_info with new filename\n",
    "    image_info['filename'] = new_filename\n",
    "    return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:12:00.162362Z",
     "iopub.status.busy": "2023-12-24T16:12:00.161482Z",
     "iopub.status.idle": "2023-12-24T16:12:00.166638Z",
     "shell.execute_reply": "2023-12-24T16:12:00.165609Z",
     "shell.execute_reply.started": "2023-12-24T16:12:00.162328Z"
    }
   },
   "outputs": [],
   "source": [
    "angles = [10, -10]  # Example rotation angles\n",
    "scale_factors = [0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:13:32.691554Z",
     "iopub.status.busy": "2023-12-24T16:13:32.691161Z",
     "iopub.status.idle": "2023-12-24T16:13:32.742480Z",
     "shell.execute_reply": "2023-12-24T16:13:32.741640Z",
     "shell.execute_reply.started": "2023-12-24T16:13:32.691522Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otman\\AppData\\Local\\Temp\\ipykernel_35656\\3437959015.py:7: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "counter = 0\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') and counter < num_augmentations_per_image:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        xml_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        for angle in angles:\n",
    "            for scale_factor in scale_factors:\n",
    "                augmented_data = augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter)\n",
    "                all_data.append(augmented_data)\n",
    "                counter += 1\n",
    "                if counter >= num_augmentations_per_image:\n",
    "                    break\n",
    "            if counter >= num_augmentations_per_image:\n",
    "                break\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(r'C:\\Users\\otman\\Downloads\\est\\augmented_csv\\dict4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:52:13.723736Z",
     "iopub.status.busy": "2023-12-24T16:52:13.723367Z",
     "iopub.status.idle": "2023-12-24T16:52:13.743885Z",
     "shell.execute_reply": "2023-12-24T16:52:13.743032Z",
     "shell.execute_reply.started": "2023-12-24T16:52:13.723710Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\2391754059.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdraw_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_annotations_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aug_0_0.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mdraw_annotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\2391754059.py\u001b[0m in \u001b[0;36mget_annotations_from_df\u001b[1;34m(df, image_filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mimage_filename\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m  \u001b[1;31m# Adjust if you have xmax, ymax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mannotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def get_annotations_from_df(df, image_filename):\n",
    "    \"\"\"Get annotations for a specific image from the DataFrame.\"\"\"\n",
    "    annotations = []\n",
    "    row = df[df['filename'] == image_filename].iloc[0]\n",
    "    for obj in row['objects']:\n",
    "        xmin, ymin = obj['coordinates']\n",
    "        xmax, ymax = xmin, ymin  # Adjust if you have xmax, ymax\n",
    "        annotations.append((xmin, ymin, xmax, ymax))\n",
    "    return annotations\n",
    "\n",
    "def draw_annotations(image_path, annotations):\n",
    "    \"\"\"Draw annotations on the image.\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for ann in annotations:\n",
    "            # Draw a rectangle for each annotation\n",
    "            draw.rectangle(ann, outline=\"red\", width=3)\n",
    "        img.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\otman\\Downloads\\est\\augmented_images\\aug_0_0.jpg'  # Replace with your image path\n",
    "\n",
    "draw_annotations(image_path, annotations)\n",
    "\n",
    "annotations = get_annotations_from_df(df, 'aug_0_0.jpg')\n",
    "draw_annotations(image_path, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>objects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug_0_0.jpg</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>[{'name': 'coin_1', 'coordinates': [84, 39]}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aug_1_0.jpg</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>[{'name': 'coin_1', 'coordinates': [94, 44]}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aug_2_0.jpg</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>[{'name': 'coin_1', 'coordinates': [42, 80]}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aug_3_0.jpg</td>\n",
       "      <td>448</td>\n",
       "      <td>448</td>\n",
       "      <td>[{'name': 'coin_1', 'coordinates': [47, 90]}, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  width  height  \\\n",
       "0  aug_0_0.jpg    448     448   \n",
       "1  aug_1_0.jpg    448     448   \n",
       "2  aug_2_0.jpg    448     448   \n",
       "3  aug_3_0.jpg    448     448   \n",
       "\n",
       "                                             objects  \n",
       "0  [{'name': 'coin_1', 'coordinates': [84, 39]}, ...  \n",
       "1  [{'name': 'coin_1', 'coordinates': [94, 44]}, ...  \n",
       "2  [{'name': 'coin_1', 'coordinates': [42, 80]}, ...  \n",
       "3  [{'name': 'coin_1', 'coordinates': [47, 90]}, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T16:49:35.833722Z",
     "iopub.status.busy": "2023-12-24T16:49:35.833041Z",
     "iopub.status.idle": "2023-12-24T16:49:35.847908Z",
     "shell.execute_reply": "2023-12-24T16:49:35.846856Z",
     "shell.execute_reply.started": "2023-12-24T16:49:35.833684Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def load_annotation(xml_file):\n",
    "    \"\"\"Load the annotation from the XML file.\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    annotations = []\n",
    "    for obj in root.iter('object'):\n",
    "        xmin = int(obj.find('bndbox').find('xmin').text)\n",
    "        ymin = int(obj.find('bndbox').find('ymin').text)\n",
    "        xmax = int(obj.find('bndbox').find('xmax').text)\n",
    "        ymax = int(obj.find('bndbox').find('ymax').text)\n",
    "        annotations.append((xmin, ymin, xmax, ymax))\n",
    "    return annotations\n",
    "\n",
    "def draw_annotations(image_path, annotations):\n",
    "    \"\"\"Draw annotations on the image.\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for ann in annotations:\n",
    "            # Draw a rectangle for each annotation\n",
    "            draw.rectangle(ann, outline=\"red\", width=2)\n",
    "        img.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\otman\\Downloads\\est\\image\\0.jpg'  # Replace with your image path\n",
    "xml_path = r'C:\\Users\\otman\\Downloads\\est\\annotation\\0.xml'  # Replace with your XML path\n",
    "\n",
    "\n",
    "\n",
    "annotations = load_annotation(xml_path)\n",
    "draw_annotations(image_path, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otman\\AppData\\Local\\Temp\\ipykernel_35656\\2274490722.py:47: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "def rotate_point(x, y, angle, cx, cy):\n",
    "    angle_rad = np.radians(angle)\n",
    "    x_new = np.cos(angle_rad) * (x - cx) - np.sin(angle_rad) * (y - cy) + cx\n",
    "    y_new = np.sin(angle_rad) * (x - cx) + np.cos(angle_rad) * (y - cy) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "def get_rotated_bbox(xmin, ymin, xmax, ymax, angle, cx, cy):\n",
    "    corners = [(xmin, ymin), (xmax, ymin), (xmin, ymax), (xmax, ymax)]\n",
    "    rotated_corners = [rotate_point(x, y, angle, cx, cy) for x, y in corners]\n",
    "\n",
    "    x_coords, y_coords = zip(*rotated_corners)\n",
    "    xmin_new, xmax_new = min(x_coords), max(x_coords)\n",
    "    ymin_new, ymax_new = min(y_coords), max(y_coords)\n",
    "\n",
    "    return [xmin_new, ymin_new, xmax_new, ymax_new]\n",
    "\n",
    "def process_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    image_info = {\n",
    "        'filename': filename,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'objects': []\n",
    "    }\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        obj_dict = {\n",
    "            'name': obj.find('name').text,\n",
    "            'coordinates': [int(obj.find('bndbox').find('xmin').text), \n",
    "                            int(obj.find('bndbox').find('ymin').text)]\n",
    "        }\n",
    "        image_info['objects'].append(obj_dict)\n",
    "\n",
    "    return image_info\n",
    "\n",
    "def augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter):\n",
    "    image = Image.open(image_path)\n",
    "    image_info = process_xml(xml_path)\n",
    "\n",
    "    scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n",
    "    rotated_image = scaled_image.rotate(angle, expand=True)\n",
    "\n",
    "    image_center = (scaled_image.width / 2, scaled_image.height / 2)\n",
    "    for obj in image_info['objects']:\n",
    "        xmin, ymin = obj['coordinates']\n",
    "        xmax, ymax = xmin, ymin  # Assuming point-based bbox\n",
    "        obj['coordinates'] = get_rotated_bbox(xmin, ymin, xmax, ymax, angle, *image_center)\n",
    "\n",
    "    new_filename = f\"aug_{counter}_{image_info['filename']}\"\n",
    "    rotated_image.save(os.path.join(output_dir, new_filename))\n",
    "\n",
    "    image_info['filename'] = new_filename\n",
    "    return image_info\n",
    "\n",
    "# Set up your parameters and paths\n",
    "angles = [10, -10]  # Example rotation angles\n",
    "scale_factors = [0.8, 0.9]  # Example scale factors\n",
    "num_augmentations_per_image = 4\n",
    "\n",
    "all_data = []\n",
    "counter = 0\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') and counter < num_augmentations_per_image:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        xml_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        for angle in angles:\n",
    "            for scale_factor in scale_factors:\n",
    "                augmented_data = augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter)\n",
    "                all_data.append(augmented_data)\n",
    "                counter += 1\n",
    "                if counter >= num_augmentations_per_image:\n",
    "                    break\n",
    "            if counter >= num_augmentations_per_image:\n",
    "                break\n",
    "                \n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(r'C:\\Users\\otman\\Downloads\\est\\augmented_csv\\dict6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otman\\AppData\\Local\\Temp\\ipykernel_35656\\2107064367.py:54: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 augmented images with bounding boxes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def rotate_point(x, y, angle, cx, cy):\n",
    "    angle_rad = np.radians(angle)\n",
    "    x_new = np.cos(angle_rad) * (x - cx) - np.sin(angle_rad) * (y - cy) + cx\n",
    "    y_new = np.sin(angle_rad) * (x - cx) + np.cos(angle_rad) * (y - cy) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "def get_transformed_bbox(bbox, angle, scale_factor, image_center):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    xmin, ymin, xmax, ymax = xmin * scale_factor, ymin * scale_factor, xmax * scale_factor, ymax * scale_factor\n",
    "\n",
    "    corners = [(xmin, ymin), (xmax, ymin), (xmin, ymax), (xmax, ymax)]\n",
    "    rotated_corners = [rotate_point(x, y, angle, *image_center) for x, y in corners]\n",
    "\n",
    "    xs, ys = zip(*rotated_corners)\n",
    "    xmin_new, ymin_new = min(xs), min(ys)\n",
    "    xmax_new, ymax_new = max(xs), max(ys)\n",
    "\n",
    "    return [xmin_new, ymin_new, xmax_new, ymax_new]\n",
    "\n",
    "def process_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find('filename').text\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    image_info = {\n",
    "        'filename': filename,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'objects': []\n",
    "    }\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        xmin = int(obj.find('bndbox').find('xmin').text)\n",
    "        ymin = int(obj.find('bndbox').find('ymin').text)\n",
    "        xmax = int(obj.find('bndbox').find('xmax').text)\n",
    "        ymax = int(obj.find('bndbox').find('ymax').text)\n",
    "        image_info['objects'].append({'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax})\n",
    "\n",
    "    return image_info\n",
    "\n",
    "def augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter):\n",
    "    image = Image.open(image_path)\n",
    "    image_info = process_xml(xml_path)\n",
    "\n",
    "    scaled_image = image.resize((int(image.width * scale_factor), int(image.height * scale_factor)), Image.ANTIALIAS)\n",
    "    rotated_image = scaled_image.rotate(angle, expand=True)\n",
    "\n",
    "    image_center = (scaled_image.width / 2, scaled_image.height / 2)\n",
    "    draw = ImageDraw.Draw(rotated_image)\n",
    "\n",
    "    for obj in image_info['objects']:\n",
    "        bbox = get_rotated_bbox(obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], angle, scale_factor, image_center)\n",
    "        draw.rectangle(bbox, outline=\"red\", width=2)\n",
    "\n",
    "    new_filename = f\"aug_{counter}_{image_info['filename']}\"\n",
    "    rotated_image.save(os.path.join(output_dir, new_filename))\n",
    "\n",
    "    return new_filename\n",
    "angles = [10, -10]  # Example rotation angles\n",
    "scale_factors = [0.8, 0.9]  # Example scale factors\n",
    "num_total_images = 50  # Total number of images you want to generate\n",
    "\n",
    "# Process and augment images\n",
    "counter = 0\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') and counter < num_total_images:\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        xml_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        for angle in angles:\n",
    "            for scale_factor in scale_factors:\n",
    "                if counter >= num_total_images:\n",
    "                    break\n",
    "                new_filename = augment_and_save(image_path, xml_path, output_dir, angle, scale_factor, counter)\n",
    "                counter += 1\n",
    "\n",
    "# Check if the required number of images are generated\n",
    "print(f\"Generated {counter} augmented images with bounding boxes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def process_xml(xml_file):\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        filename = root.find('filename').text\n",
    "        size = root.find('size')\n",
    "        width = int(size.find('width').text)\n",
    "        height = int(size.find('height').text)\n",
    "\n",
    "        image_info = {\n",
    "            'filename': filename,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'objects': []\n",
    "        }\n",
    "\n",
    "        for obj in root.iter('object'):\n",
    "            xmin = int(float(obj.find('bndbox').find('xmin').text))\n",
    "            ymin = int(float(obj.find('bndbox').find('ymin').text))\n",
    "            image_info['objects'].append({'name': obj.find('name').text, 'coordinates': [xmin, ymin]})\n",
    "\n",
    "        return image_info\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing file {xml_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def flip_horizontal(bbox, image_width):\n",
    "    xmin, ymin = bbox\n",
    "    return [image_width - xmin, ymin]\n",
    "\n",
    "def flip_vertical(bbox, image_height):\n",
    "    xmin, ymin = bbox\n",
    "    return [xmin, image_height - ymin]\n",
    "\n",
    "def draw_bounding_box(image, bbox):\n",
    "    xmin, ymin = bbox\n",
    "    cv2.circle(image, (int(xmin), int(ymin)), radius=2, color=(0, 255, 0), thickness=4)\n",
    "\n",
    "\n",
    "def rotate_point(x, y, angle, cx, cy):\n",
    "    angle_rad = np.radians(angle)\n",
    "    x_new = np.cos(angle_rad) * (x - cx) - np.sin(angle_rad) * (y - cy) + cx\n",
    "    y_new = np.sin(angle_rad) * (x - cx) + np.cos(angle_rad) * (y - cy) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "def rotate_bbox(bbox, angle, image_center):\n",
    "    xmin, ymin = bbox\n",
    "    rotated = rotate_point(xmin, ymin, angle, *image_center)\n",
    "    return rotated\n",
    "image_directory = r'C:\\Users\\otman\\Downloads\\est\\image'\n",
    "xml_directory = r'C:\\Users\\otman\\Downloads\\est\\annotation'\n",
    "output_directory = r'C:\\Users\\otman\\Downloads\\est\\transformed_images'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_directory_drawn = r'C:\\Users\\otman\\Downloads\\est\\transformed_images_drawn'\n",
    "os.makedirs(output_directory_drawn, exist_ok=True)\n",
    "xml_output_path=r'C:\\Users\\otman\\Downloads\\est\\transformed_xml'\n",
    "os.makedirs(xml_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations_and_save(image_dir, xml_dir, output_dir, output_dir_drawn, transformations):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            xml_path = os.path.join(xml_dir, filename.replace('.jpg', '.xml'))\n",
    "            data = process_xml(xml_path)\n",
    "\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Unable to read image: {filename}\")\n",
    "                continue\n",
    "            image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "            for transformation in transformations:\n",
    "                if transformation['type'] == 'flip_horizontal':\n",
    "                    image = cv2.flip(image, 1)\n",
    "                    suffix = '_horizontal'\n",
    "                    update_function = flip_horizontal\n",
    "                elif transformation['type'] == 'flip_vertical':\n",
    "                    image = cv2.flip(image, 0)\n",
    "                    suffix = '_vertical'\n",
    "                    update_function = flip_vertical\n",
    "                elif transformation['type'] == 'rotate':\n",
    "                    angle = transformation.get('angle', 90)\n",
    "                    M = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "                    image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "                    suffix = f'_rotated_{angle}'\n",
    "                    update_function = lambda bbox, img_shape: rotate_bbox(bbox, angle, image_center)\n",
    "\n",
    "                new_filename = os.path.splitext(filename)[0] + suffix + os.path.splitext(filename)[1]\n",
    "                cv2.imwrite(os.path.join(output_dir, new_filename), image)\n",
    "\n",
    "                # Draw bounding boxes and save the drawn image\n",
    "                image_with_bbox = image.copy()\n",
    "                for obj in data['objects']:\n",
    "                    obj['coordinates'] = update_function(obj['coordinates'], image.shape[1 if suffix == '_horizontal' else 0])\n",
    "                    draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "\n",
    "                data['filename'] = new_filename\n",
    "\n",
    "# Example usage\n",
    "image_directory = r'C:\\Users\\otman\\Downloads\\est\\image'\n",
    "xml_directory = r'C:\\Users\\otman\\Downloads\\est\\annotation'\n",
    "output_directory = r'C:\\Users\\otman\\Downloads\\est\\transformed_images'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_directory_drawn = r'C:\\Users\\otman\\Downloads\\est\\transformed_images_drawn'\n",
    "os.makedirs(output_directory_drawn, exist_ok=True)\n",
    "xml_output_path=r'C:\\Users\\otman\\Downloads\\est\\transformed_xml'\n",
    "os.makedirs(xml_output_path, exist_ok=True)\n",
    "transformations = [{'type': 'flip_horizontal'}, {'type': 'flip_vertical'}]\n",
    "\n",
    "apply_transformations_and_save(image_directory, xml_directory, output_directory, output_directory_drawn, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xml(data, xml_output_path, bbox_size=(20, 20)):\n",
    "    root = ET.Element(\"annotation\")\n",
    "\n",
    "    # Add elements to the XML as per your schema\n",
    "    filename = ET.SubElement(root, \"filename\")\n",
    "    filename.text = data['filename']\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    width = ET.SubElement(size, \"width\")\n",
    "    width.text = str(data['width'])\n",
    "    height = ET.SubElement(size, \"height\")\n",
    "    height.text = str(data['height'])\n",
    "    depth = ET.SubElement(size, \"depth\")\n",
    "    depth.text = \"3\"  # Assuming all images are RGB\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        obj_elem = ET.SubElement(root, \"object\")\n",
    "        name = ET.SubElement(obj_elem, \"name\")\n",
    "        name.text = obj['name']\n",
    "\n",
    "        bndbox = ET.SubElement(obj_elem, \"bndbox\")\n",
    "        xmin = ET.SubElement(bndbox, \"xmin\")\n",
    "        xmin.text = str(obj['coordinates'][0])\n",
    "        ymin = ET.SubElement(bndbox, \"ymin\")\n",
    "        ymin.text = str(obj['coordinates'][1])\n",
    "        xmax = ET.SubElement(bndbox, \"xmax\")\n",
    "        xmax.text = str(obj['coordinates'][0] + bbox_size[0])  # Calculate xmax\n",
    "        ymax = ET.SubElement(bndbox, \"ymax\")\n",
    "        ymax.text = str(obj['coordinates'][1] + bbox_size[1])   # Assuming ymax is stored\n",
    "\n",
    "    tree = ET.ElementTree(root)\n",
    "    tree.write(xml_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_horizontal_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    # Apply horizontal flip\n",
    "    image_flipped = cv2.flip(image, 1)\n",
    "    for obj in data['objects']:\n",
    "        obj['coordinates'] = flip_horizontal(obj['coordinates'], image.shape[1])\n",
    "\n",
    "    # Save the flipped image\n",
    "    new_filename = os.path.splitext(filename)[0] + '_horizontal' + os.path.splitext(filename)[1]\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), image_flipped)\n",
    "\n",
    "    # Draw bounding boxes and save the image\n",
    "    image_with_bbox = image_flipped.copy()\n",
    "    for obj in data['objects']:\n",
    "        draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "    \n",
    "    data['filename'] = new_filename\n",
    "\n",
    "    # Save the updated XML\n",
    "    xml_output_path = os.path.join(xml_directory, new_filename.replace('.jpg', '.xml'))\n",
    "    save_xml(data, xml_output_path)\n",
    "    \n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Apply transformations\n",
    "        apply_horizontal_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vertical_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    # Apply vertical flip\n",
    "    image_flipped = cv2.flip(image, 0)\n",
    "    for obj in data['objects']:\n",
    "        obj['coordinates'] = flip_vertical(obj['coordinates'], image.shape[0])\n",
    "\n",
    "    # Save the flipped image\n",
    "    new_filename = os.path.splitext(filename)[0] + '_vertical' + os.path.splitext(filename)[1]\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), image_flipped)\n",
    "\n",
    "    # Draw bounding boxes and save the image\n",
    "    image_with_bbox = image_flipped.copy()\n",
    "    for obj in data['objects']:\n",
    "        draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "    data['filename'] = new_filename\n",
    "\n",
    "    # Save the updated XML\n",
    "    xml_output_path = os.path.join(xml_directory, new_filename.replace('.jpg', '.xml'))\n",
    "    save_xml(data, xml_output_path)\n",
    "    \n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Apply transformations\n",
    "        apply_vertical_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotation_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename, angle):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "    M = cv2.getRotationMatrix2D(image_center, angle, 1)\n",
    "    image_rotated = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    for obj in data['objects']:\n",
    "        obj['coordinates'] = rotate_bbox(obj['coordinates'], angle, image_center)\n",
    "\n",
    "    # Save the rotated image\n",
    "    new_filename = os.path.splitext(filename)[0] + f'_rotated_{angle}' + os.path.splitext(filename)[1]\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), image_rotated)\n",
    "\n",
    "    # Draw bounding boxes and save the image\n",
    "    image_with_bbox = image_rotated.copy()\n",
    "    for obj in data['objects']:\n",
    "        draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "    \n",
    "    data['filename'] = new_filename\n",
    "\n",
    "    # Save the updated XML\n",
    "    xml_output_path = os.path.join(xml_directory, new_filename.replace('.jpg', '.xml'))\n",
    "    save_xml(data, xml_output_path)\n",
    "\n",
    "angle = 180  # Rotation angle\n",
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "        apply_rotation_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image_and_boxes(image, bbox_list, scale_factor, bbox_size=(20, 20)):\n",
    "    new_size = (int(image.shape[1] * scale_factor), int(image.shape[0] * scale_factor))\n",
    "    scaled_image = cv2.resize(image, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    scaled_bbox_list = []\n",
    "    for bbox in bbox_list:\n",
    "        xmin, ymin = bbox\n",
    "        xmax, ymax = xmin + bbox_size[0], ymin + bbox_size[1]\n",
    "        scaled_bbox = [int(xmin * scale_factor), int(ymin * scale_factor),\n",
    "                       int(xmax * scale_factor), int(ymax * scale_factor)]\n",
    "        scaled_bbox_list.append(scaled_bbox)\n",
    "\n",
    "    return scaled_image, scaled_bbox_list\n",
    "\n",
    "def apply_scaling_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename, scale_factor):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    scaled_image, scaled_bbox_list = scale_image_and_boxes(image, [obj['coordinates'] for obj in data['objects']], scale_factor)\n",
    "\n",
    "    # Update the filename and bounding boxes in the data dictionary\n",
    "    data['filename'] = os.path.splitext(filename)[0] + f'_scaled_{scale_factor}' + os.path.splitext(filename)[1]\n",
    "    for obj, new_bbox in zip(data['objects'], scaled_bbox_list):\n",
    "        obj['coordinates'] = new_bbox\n",
    "\n",
    "    # Save the scaled image and XML\n",
    "    new_filename = data['filename']\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), scaled_image)\n",
    "    save_xml(data, os.path.join(xml_directory, new_filename.replace('.jpg', '.xml')))\n",
    "\n",
    "    # Draw bounding boxes and save the image\n",
    "    image_with_bbox = scaled_image.copy()\n",
    "    for new_bbox in scaled_bbox_list:\n",
    "        draw_bounding_box(image_with_bbox, new_bbox)\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "def draw_bounding_box(image, bbox):\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "\n",
    "    # Drawing a rectangle around the bounding box\n",
    "    cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "\n",
    "# Example usage\n",
    "scale_factor = 0.5  # Example scale factor\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "        apply_scaling_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename, scale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, bbox):\n",
    "    xmin, ymin = bbox\n",
    "    cv2.circle(image, (int(xmin), int(ymin)), radius=2, color=(0, 255, 0), thickness=4)\n",
    "\n",
    "def add_gaussian_noise(image):\n",
    "    row, col, ch = image.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    gauss = gauss.reshape(row, col, ch)\n",
    "    noisy_image = image + gauss\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "def apply_noise_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    noisy_image = add_gaussian_noise(image)\n",
    "\n",
    "    # Save the noisy image\n",
    "    new_filename = os.path.splitext(filename)[0] + '_noisy' + os.path.splitext(filename)[1]\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), noisy_image)\n",
    "\n",
    "    # Update the filename in the data dictionary and save the XML\n",
    "    data['filename'] = new_filename\n",
    "    xml_output_path = os.path.join(xml_directory, new_filename.replace('.jpg', '.xml'))\n",
    "    save_xml(data, xml_output_path)\n",
    "\n",
    "    # Draw bounding boxes on the noisy image for visualization\n",
    "    image_with_bbox = noisy_image.copy()\n",
    "    for obj in data['objects']:\n",
    "        draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "    \n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "        apply_noise_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness(image, brightness_factor):\n",
    "    # Ensure the brightness factor is within a reasonable range\n",
    "    brightness_factor = max(min(brightness_factor, 2.0), 0)  # Restricting between 0 and 2\n",
    "\n",
    "    adjusted_image = image * brightness_factor\n",
    "    adjusted_image = np.clip(adjusted_image, 0, 255)  # Ensuring the values are within 0-255\n",
    "    return adjusted_image.astype(np.uint8)\n",
    "\n",
    "def apply_brightness_and_save(image_path, xml_path, output_dir, output_dir_drawn, filename, brightness_factor):\n",
    "    data = process_xml(xml_path)\n",
    "    if data is None:\n",
    "        print(f\"Unable to process XML: {filename}\")\n",
    "        return\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to read image: {filename}\")\n",
    "        return\n",
    "\n",
    "    bright_image = adjust_brightness(image.astype(np.float32)/255, brightness_factor)\n",
    "\n",
    "    # Save the brightened image\n",
    "    new_filename = os.path.splitext(filename)[0] + f'_bright_{brightness_factor}' + os.path.splitext(filename)[1]\n",
    "    cv2.imwrite(os.path.join(output_dir, new_filename), (bright_image * 255).astype(np.uint8))\n",
    "\n",
    "    # Draw bounding boxes and save the image\n",
    "    image_with_bbox = (bright_image * 255).astype(np.uint8).copy()\n",
    "    for obj in data['objects']:\n",
    "        draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "    cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "\n",
    "    # Update the filename in the data dictionary and save the XML\n",
    "    data['filename'] = new_filename\n",
    "    save_xml(data, os.path.join(xml_directory, new_filename.replace('.jpg', '.xml')))\n",
    "\n",
    "# Example usage\n",
    "brightness_factor = 1.5  # Example brightness factor\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "        apply_brightness_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename, brightness_factor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_transformations_and_save(image_dir, xml_dir, output_dir, output_dir_drawn, transformations):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if not os.path.exists(output_dir_drawn):\n",
    "        os.makedirs(output_dir_drawn)\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            xml_path = os.path.join(xml_dir, filename.replace('.jpg', '.xml'))\n",
    "            data = process_xml(xml_path)\n",
    "\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Unable to read image: {filename}\")\n",
    "                continue\n",
    "\n",
    "            image_center = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "\n",
    "            for transformation in transformations:\n",
    "                image_transformed = image.copy()\n",
    "\n",
    "                if transformation['type'] == 'flip_horizontal':\n",
    "                    image_transformed = cv2.flip(image_transformed, 1)\n",
    "                    suffix = '_horizontal'\n",
    "                    for obj in data['objects']:\n",
    "                        obj['coordinates'] = flip_horizontal(obj['coordinates'], image.shape[1])\n",
    "                elif transformation['type'] == 'flip_vertical':\n",
    "                    image_transformed = cv2.flip(image_transformed, 0)\n",
    "                    suffix = '_vertical'\n",
    "                    for obj in data['objects']:\n",
    "                        # Update the bbox for the flipped image\n",
    "                        obj['coordinates'] = flip_vertical(obj['coordinates'], image.shape[0])\n",
    "                elif transformation['type'] == 'rotate':\n",
    "                    angle = transformation['angle']\n",
    "                    M = cv2.getRotationMatrix2D(image_center, angle, 1)\n",
    "                    image_transformed = cv2.warpAffine(image_transformed, M, (image.shape[1], image.shape[0]))\n",
    "                    suffix = f'_rotated_{angle}'\n",
    "                    for obj in data['objects']:\n",
    "                        obj['coordinates'] = rotate_bbox(obj['coordinates'], angle, image_center)\n",
    "\n",
    "                new_filename = os.path.splitext(filename)[0] + suffix + os.path.splitext(filename)[1]\n",
    "                cv2.imwrite(os.path.join(output_dir, new_filename), image_transformed)\n",
    "\n",
    "                # Draw bounding boxes and save the drawn image\n",
    "                image_with_bbox = image_transformed.copy()\n",
    "                for obj in data['objects']:\n",
    "                    draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "\n",
    "                data['filename'] = new_filename\n",
    "\n",
    "# Example usage\n",
    "image_directory = r'C:\\Users\\otman\\Downloads\\est\\image'\n",
    "xml_directory = r'C:\\Users\\otman\\Downloads\\est\\annotation'\n",
    "output_directory = r'C:\\Users\\otman\\Downloads\\est\\transformed_images'\n",
    "output_directory_drawn = r'C:\\Users\\otman\\Downloads\\est\\transformed_images_drawn'\n",
    "transformations = [\n",
    "    {'type': 'flip_horizontal'}, \n",
    "    {'type': 'flip_vertical'},\n",
    "    {'type': 'rotate', 'angle': 90}  # Example rotation angle\n",
    "]\n",
    "\n",
    "apply_transformations_and_save(image_directory, xml_directory, output_directory, output_directory_drawn, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations_and_save(image_dir, xml_dir, output_dir, output_dir_drawn, transformations):\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            xml_path = os.path.join(xml_dir, filename.replace('.jpg', '.xml'))\n",
    "            data = process_xml(xml_path)\n",
    "\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Unable to read image: {filename}\")\n",
    "                continue\n",
    "\n",
    "            for transformation in transformations:\n",
    "                transformed_image = image.copy()\n",
    "\n",
    "                if transformation['type'] == 'flip_horizontal':\n",
    "                    image = cv2.flip(image, 1)\n",
    "                    suffix = '_horizontal'\n",
    "                    update_function = flip_horizontal\n",
    "                elif transformation['type'] == 'flip_vertical':\n",
    "                    image = cv2.flip(image, 0)\n",
    "                    suffix = '_vertical'\n",
    "                    update_function = flip_vertical\n",
    "\n",
    "                new_filename = os.path.splitext(filename)[0] + suffix + os.path.splitext(filename)[1]\n",
    "                cv2.imwrite(os.path.join(output_dir, new_filename), image)\n",
    "\n",
    "                # Draw bounding boxes and save the drawn image\n",
    "                image_with_bbox = image.copy()\n",
    "                for obj in data['objects']:\n",
    "                    obj['coordinates'] = update_function(obj['coordinates'], image.shape[1 if suffix == '_horizontal' else 0])\n",
    "                    draw_bounding_box(image_with_bbox, obj['coordinates'])\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_dir_drawn, new_filename), image_with_bbox)\n",
    "\n",
    "                data['filename'] = new_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    {'type': 'flip_horizontal'}, \n",
    "    {'type': 'flip_vertical'},\n",
    "    {'type': 'rotate', 'angle': 90}  # Example rotation angle\n",
    "]\n",
    "\n",
    "apply_transformations_and_save(image_directory, xml_directory, output_directory, output_directory_drawn, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rotate_bbox() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\2183640647.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mapply_horizontal_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory_drawn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mapply_vertical_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory_drawn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mapply_rotation_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory_drawn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\1956011430.py\u001b[0m in \u001b[0;36mapply_rotation_and_save\u001b[1;34m(image_path, xml_path, output_dir, output_dir_drawn, filename, angle)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Update bounding box coordinates based on the rotation angle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotate_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Save the rotated image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: rotate_bbox() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "        # Apply transformations\n",
    "        apply_horizontal_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename)\n",
    "        apply_vertical_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename)\n",
    "        apply_rotation_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rotate_bbox() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\576468310.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mxml_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mapply_rotation_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxml_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_directory_drawn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35656\\1956011430.py\u001b[0m in \u001b[0;36mapply_rotation_and_save\u001b[1;34m(image_path, xml_path, output_dir, output_dir_drawn, filename, angle)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Update bounding box coordinates based on the rotation angle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotate_bbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coordinates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_center\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Save the rotated image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: rotate_bbox() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        xml_path = os.path.join(xml_directory, filename.replace('.jpg', '.xml'))\n",
    "        apply_rotation_and_save(image_path, xml_path, output_directory, output_directory_drawn, filename, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_dir, xml_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            xml_path = os.path.join(xml_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "            # Read and preprocess the image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))  # Resize for the model\n",
    "            images.append(image)\n",
    "\n",
    "            # Parse the XML to get the points\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            points = []\n",
    "            for member in root.findall('object'):\n",
    "                # Assuming each 'object' element contains one point with (xmin, ymin, xmax, ymax)\n",
    "                xmin = int(float(member.find('bndbox').find('xmin').text))\n",
    "                ymin = int(float(member.find('bndbox').find('ymin').text))\n",
    "                # Optionally, calculate the center or any specific point from (xmin, ymin, xmax, ymax)\n",
    "                points.extend([xmin, ymin])  # Adjust according to your requirement\n",
    "            labels.append(points)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "image_directory = r'C:\\Users\\otman\\Downloads\\est\\transformed_images'\n",
    "xml_directory = r'C:\\Users\\otman\\Downloads\\est\\annotation'\n",
    "\n",
    "train_images, train_labels = load_data(image_directory, xml_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def normalize_labels(labels, image_size=(448, 448)):\n",
    "    # Normalize labels to be between 0 and 1\n",
    "    normalized_labels = []\n",
    "    for label in labels:\n",
    "        normalized_label = []\n",
    "        for i in range(0, len(label), 2):\n",
    "            normalized_label.extend([label[i] / image_size[0], label[i+1] / image_size[1]])\n",
    "        normalized_labels.append(normalized_label)\n",
    "    return np.array(normalized_labels)\n",
    "\n",
    "normalized_train_labels = normalize_labels(train_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, normalized_train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Concatenate, Activation, Flatten, Dense\n",
    "def create_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Middle\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    # Decoder\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
    "    concat4 = Concatenate(axis=-1)([conv2, up4])\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(concat4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
    "    concat5 = Concatenate(axis=-1)([conv1, up5])\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(concat5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer for point prediction\n",
    "    flattened = Flatten()(conv5)\n",
    "    dense_layer = Dense(128, activation='relu')(flattened)\n",
    "    output_layer = Dense(8, activation='sigmoid')(dense_layer)  # 8 values for 4 points (x, y)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 835s 88s/step - loss: 0.3096 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "6/9 [===================>..........] - ETA: 4:13 - loss: 0.3015"
     ]
    }
   ],
   "source": [
    "model = create_model((224,224,3))\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 83ms/step - loss: 0.2134\n",
      "Test loss: 0.2133806347846985\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otman\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\otman\\Downloads\\est\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "Predicted points: [ 2.47182477 -0.02691932  6.50476754 -1.60085137  3.08626473 -2.6095067\n",
      " -0.69678748  3.64408207]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the image\n",
    "new_image_path = r'C:\\Users\\otman\\Downloads\\est\\image\\0.jpg'  # Replace with your image path\n",
    "\n",
    "model = load_model(r'C:\\Users\\otman\\Downloads\\est\\model.h5')  # Adjust the path to your model\n",
    "\n",
    "def create_directory(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    preprocessed_image = cv2.resize(image, (224, 224))  # Resize as per model's input shape\n",
    "    return preprocessed_image, image  # Return both preprocessed and original image\n",
    "\n",
    "def draw_points_on_image(image, points):\n",
    "    for i in range(0, len(points), 2):\n",
    "        x, y = int(points[i]), int(points[i+1])\n",
    "        cv2.circle(image, (x, y), radius=5, color=(0, 255, 0), thickness=-1)\n",
    "    return image\n",
    "\n",
    "predicted_directory = r'C:\\Users\\otman\\Downloads\\est\\predicted'\n",
    "create_directory(predicted_directory)\n",
    "\n",
    "preprocessed_image, original_image = load_and_preprocess_image(new_image_path)\n",
    "\n",
    "# Predict points using the model\n",
    "predictions = model.predict(np.expand_dims(preprocessed_image / 255.0, axis=0))\n",
    "predicted_points = predictions[0]\n",
    "\n",
    "# Assuming points are normalized, rescale them back\n",
    "predicted_points = np.array([predicted_points[i] * original_image.shape[1] if i % 2 == 0 else predicted_points[i] * original_image.shape[0] for i in range(len(predicted_points))])\n",
    "\n",
    "# Draw the points on the original image\n",
    "output_image = draw_points_on_image(original_image.copy(), predicted_points)\n",
    "\n",
    "print(\"Predicted points:\", predicted_points)\n",
    "# Save the image with drawn points\n",
    "output_filename = os.path.basename(new_image_path).replace('.jpg', '_predicted.jpg')\n",
    "cv2.imwrite(os.path.join(predicted_directory, output_filename), cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4216253,
     "sourceId": 7272859,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
